# emotion_classifier_18emo_peft.py
# 需要安装 sentence-transformers, peft, accelerate 库
import torch
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from transformers import (
    AutoModel,
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
    TrainerCallback,
)
from peft import get_peft_model, LoraConfig, TaskType  #

import os
import json
import logging

# 配置日志记录
logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

# 固定随机种子保证可复现
SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)

# 明确定义18类情绪及其顺序（关键！）
TARGET_EMOTIONS = [
    "高兴",
    "厌恶",
    "害羞",
    "害怕",
    "生气",
    "认真",
    "紧张",
    "慌张",
    "疑惑",
    "兴奋",
    "无奈",
    "担心",
    "惊讶",
    "哭泣",
    "心动",
    "难为情",
    "自信",
    "调皮",
]
NUM_LABELS = len(TARGET_EMOTIONS)  # 获取标签数量


class FileLoggingCallback(TrainerCallback):
    """
    一个自定义的回调类，用于将训练过程中的日志（如loss, acc等）
    实时写入到一个JSON Lines文件中。
    generated by gemini-2.5-pro
    """

    def __init__(self, log_file_path):
        super().__init__()
        self.log_file_path = log_file_path
        # 在训练开始时清空或创建日志文件
        with open(self.log_file_path, "w", encoding="utf-8") as f:
            f.write("")  # 创建或清空文件

    def on_log(self, args, state, control, logs=None, **kwargs):
        """
        在每个日志记录步骤被调用。
        """
        if logs is not None:
            # 附加全局步骤数到日志中，便于追踪
            log_record = {"step": state.global_step, **logs}
            # 以追加模式打开文件并写入新的日志记录
            with open(self.log_file_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(log_record, ensure_ascii=False) + "\n")


def load_data(data_path="emotion_data_manual.csv"):
    """加载并预处理数据，强制使用定义的情绪标签"""
    try:
        data = pd.read_csv(data_path)
    except FileNotFoundError:
        log.error(f"错误：数据文件 '{data_path}' 未找到。请确保文件存在于正确路径。")
        exit()

    data["label"] = data["label"].astype(str)
    data = data[data["label"].isin(TARGET_EMOTIONS)].copy()
    data["text"] = data["text"].astype(str)

    if data.empty:
        log.error(f"错误：在 '{data_path}' 中没有找到属于 TARGET_EMOTIONS 的数据。")
        exit()

    log.info("\n=== 数据统计 ===")
    log.info(f"目标情绪类别数量: {NUM_LABELS}")
    log.info(f"筛选后总样本数: {len(data)}")
    log.info(f"类别分布:\n{data['label'].value_counts()}")

    label_encoder = LabelEncoder()
    label_encoder.fit(TARGET_EMOTIONS)

    test_size = 0.2
    try:
        train_texts, test_texts, train_labels, test_labels = train_test_split(
            data["text"].tolist(),
            data["label"].tolist(),
            test_size=test_size,
            stratify=data["label"],
            random_state=SEED,
        )
    except ValueError:
        log.warning("分层抽样失败，可能某些类别样本过少。退回到普通随机抽样...")
        train_texts, test_texts, train_labels, test_labels = train_test_split(
            data["text"].tolist(), data["label"].tolist(), test_size=test_size, random_state=SEED
        )

    train_labels_encoded = label_encoder.transform(train_labels)
    test_labels_encoded = label_encoder.transform(test_labels)

    log.info(f"\n划分结果: 训练集={len(train_texts)}, 测试集={len(test_texts)}")
    log.info(f"测试集类别分布:\n{pd.Series(test_labels).value_counts().sort_index()}")

    test_unique_labels = set(test_labels)
    if len(test_unique_labels) < NUM_LABELS:
        log.warning(
            f"警告：测试集仅包含 {len(test_unique_labels)}/{NUM_LABELS} 个类别。"
            f"缺失的类别：{set(TARGET_EMOTIONS) - test_unique_labels}"
        )

    log.info(f"标签映射: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}")

    return train_texts, test_texts, train_labels_encoded, test_labels_encoded, label_encoder


class EmotionDataset(torch.utils.data.Dataset):
    """自定义数据集类"""

    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.as_tensor(val[idx]) for key, val in self.encodings.items()}
        item["labels"] = torch.as_tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)


def train_and_evaluate():
    """训练和评估18类情绪分类模型，并保存日志和结果"""
    # 1. 加载数据
    train_texts, test_texts, train_labels, test_labels, label_encoder = load_data()

    # 2. 初始化模型和分词器
    model_name = "BAAI/bge-base-zh-v1.5"
    log.info(f"使用基座模型: {model_name}")
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)

    # 定义LoRA配置
    peft_config = LoraConfig(
        # task_type=TaskType.SEQUENCE_CLASSIFICATION,
        task_type="SEQ_CLS",  # 似乎是因为版本问题上面的写法会报错
        inference_mode=False,
        r=32,
        lora_alpha=64,  # 通常是r的两倍
        lora_dropout=0.2,
        target_modules=[
            "key",
            "query",
            "value",
        ],  # 根据模型表现可以去除"key", 但是推理显存占用也就少几MB真的有必要吗(？
    )

    base_model = AutoModelForSequenceClassification.from_pretrained(
        model_name,
        num_labels=NUM_LABELS,
        id2label={i: label for i, label in enumerate(label_encoder.classes_)},
        label2id={label: i for i, label in enumerate(label_encoder.classes_)},
    )
    model = get_peft_model(base_model, peft_config)

    # 3. 数据编码
    log.info("\nTokenizing 数据...")
    train_encodings = tokenizer(train_texts, truncation=True, padding="max_length", max_length=128)
    test_encodings = tokenizer(test_texts, truncation=True, padding="max_length", max_length=128)

    # 4. 创建数据集
    train_dataset = EmotionDataset(train_encodings, train_labels)
    test_dataset = EmotionDataset(test_encodings, test_labels)

    output_dir_base = "./results_18emo_output"
    os.makedirs(output_dir_base, exist_ok=True)

    training_log_path = os.path.join(output_dir_base, "training_log.jsonl")
    final_report_path = os.path.join(output_dir_base, "final_performance_report.json")
    final_model_dir = os.path.join(output_dir_base, "emotion_model_18emo")
    base_model_dir = os.path.join(output_dir_base, "emotion_model_18emo/base_model")

    log.info(f"所有输出将被保存到: {os.path.abspath(output_dir_base)}")
    log.info(f"训练日志文件: {training_log_path}")
    log.info(f"最终性能报告文件: {final_report_path}")
    log.info(f"最终模型目录: {final_model_dir}")
    log.info(f"原模型目录: {base_model_dir}")

    # 5. 训练配置
    training_args = TrainingArguments(
        output_dir=output_dir_base,
        num_train_epochs=16,  # PEFT可以适当增加epoch或学习率
        per_device_train_batch_size=16,
        per_device_eval_batch_size=32,
        learning_rate=1e-4,  # 同上
        weight_decay=0.01,
        warmup_ratio=0.1,
        eval_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        metric_for_best_model="f1_weighted",
        logging_dir=f"{output_dir_base}/logs",
        logging_steps=50,
        seed=SEED,
        fp16=torch.cuda.is_available(),
        report_to="all",
    )

    # 6. 自定义评估指标
    def compute_metrics(pred):
        labels = pred.label_ids
        preds = pred.predictions.argmax(-1)
        # 使用 label_encoder.classes_ 获取正确的标签名称顺序
        report = classification_report(
            labels,
            preds,
            target_names=label_encoder.classes_,
            output_dict=True,
            zero_division=0,  # 处理某个类别在预测或真实标签中都没有出现的情况
        )
        # 返回 Trainer 需要的指标
        return {
            "accuracy": report["accuracy"],
            "f1_weighted": report["weighted avg"]["f1-score"],
            "precision_weighted": report["weighted avg"]["precision"],
            "recall_weighted": report["weighted avg"]["recall"],
        }

    file_logging_callback = FileLoggingCallback(training_log_path)

    # 7. 训练
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        compute_metrics=compute_metrics,
        tokenizer=tokenizer,  # 传递 tokenizer 方便 Trainer 处理 padding
        callbacks=[file_logging_callback],  # 将自定义回调添加到列表中
    )

    log.info("\n开始训练 (PEFT/LoRA)...")
    trainer.train()
    log.info("训练完成。")

    # 8. 最终评估 (加载最好的模型进行评估)
    log.info("\n=== 测试集最终性能 (使用最佳模型) ===")
    eval_results = trainer.evaluate(test_dataset)
    log.info(f"评估结果: {eval_results}")

    # 获取详细的分类报告
    log.info("\n详细分类报告:")
    predictions = trainer.predict(test_dataset)
    y_pred = np.argmax(predictions.predictions, axis=1)
    classification_report_str = classification_report(
        test_labels, y_pred, target_names=label_encoder.classes_, digits=4
    )
    print(classification_report_str)

    log.info(f"\n正在将最终评估报告保存到: {final_report_path}...")

    # 以字典形式获取报告，方便存为JSON
    detailed_report_dict = classification_report(
        test_labels, y_pred, target_names=label_encoder.classes_, digits=4, output_dict=True
    )
    final_results_to_save = {"evaluation_summary": eval_results, "classification_report": detailed_report_dict}
    with open(final_report_path, "w", encoding="utf-8") as f:
        json.dump(final_results_to_save, f, ensure_ascii=False, indent=4)
    log.info("评估报告已成功保存。")

    # 9. 保存模型和配置
    os.makedirs(final_model_dir, exist_ok=True)
    log.info(f"\n正在保存最佳模型到: {final_model_dir}...")
    trainer.save_model(final_model_dir)  # 只会保存adapter的权重和配置文件
    os.makedirs(base_model_dir, exist_ok=True)
    AutoModel.from_pretrained(model_name).save_pretrained(base_model_dir)
    tokenizer.save_pretrained(base_model_dir)

    # 保存标签映射
    label_mapping_path = os.path.join(final_model_dir, "label_mapping.json")
    log.info(f"正在保存标签映射到: {label_mapping_path}...")
    # *** FIX: Added encoding='utf-8' to open() ***
    with open(label_mapping_path, "w", encoding="utf-8") as f:
        json.dump(
            {
                # 确保 key 是字符串，因为 JSON 的 key 必须是 string
                "id2label": {str(i): label for i, label in enumerate(label_encoder.classes_)},
                "label2id": {label: i for i, label in enumerate(label_encoder.classes_)},
            },
            f,
            ensure_ascii=False,
            indent=2,
        )

    log.info(f"\n模型和配置已全部保存到: {final_model_dir}")


# *** FIX: Corrected if __name__ == "__main__": ***
if __name__ == "__main__":
    train_and_evaluate()
